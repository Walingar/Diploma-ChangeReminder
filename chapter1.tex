Перед началом выполнения выпускной квалификационной работы следует поставить цель и задачи, которые помогут достигнуть заданной цели. Цель будет основана на некоторых определениях и понятиях, о них и будет рассказано в данной главе.
\section{Машинное обучение}
Начало обзора предметной области будет посвящено такой дисциплине как машинное обучение. В современном мире информационных технологий слово <<предсказание>> у многих сразу ассоциируется с термином машинное обучение. И данная работа не исключение, в ней за основу модели предсказаний также будет выступать модель машинного обучения. 

Машинное обучение (далее может использоваться как ML, от английского Machine Learning)~--- это раздел науки о создании интеллектуальных алгоритмов, изучающий методы, которые строят математическую модель, решающую поставленную задачу, а не решают задачу напрямую \cite{ml-main-book}. Машинное обучение бывает двух типов: по прецедентам и дедуктивное. В современном мире можно считать, что машинное обучение и обучение по прецедентам~--- это одно и то же, поэтому будем говорить именно об этом типе обучения. Оно основано на создании математической модели, используя раннее эмпирически собранный набор данных. В свою очередь, машинное обучение подразделяется на несколько способов: обучение с учителем, обучение без учителя, обучение с подкреплением, активное обучение и много других видов \cite{ml-methods-book}. Рассмотрим подробнее способ, который будет использоваться в работе, обучение с учителем.
    \subsection{Обучение с учителем}
Обучение с учителем~--- способ машинного обучения, в ходе которого математическая модель обучается на наборе данных состоящим из пар входные данные и выходные данные \cite{ml-methods-book}. Обученная модель должна получать входные данные в том же формате, что и данные в исходном наборе данных и возвращать выходные. Модель обучается таким образом, чтобы метрика между выходными данными модели и выходными данными в наборе было минимальным. Метрика задается отдельно для каждой задачи. Важным моментом в процессе минимизации метрики является то, что нельзя проверять её на тех же данных, на которых происходило обучение \cite{cross-validation-article}. Распространённым методом анализа поведения обученной математической модели на независимых данных является перекрёстная проверка. 
    \subsection{Перекрёстная проверка}
Перекрёстная проверка~--- метод оценки математической модели на независимых данных \cite{cross-validation-article}. Этот метод является одним из самых используемых инструментов в машинном обучении. Перекрёстная проверка заключается в разбиении имеющейся выборки на $k$ частей. $k - 1$ часть используется для обучения математической модели, оставшаяся часть используется для оценки качества обученной модели. Этот шаг повторяется $k$ раз, чтобы каждая часть поучаствовала в оценке качества независимо. Таким образом, усреднив полученные результаты, будет получена наиболее вероятная оценка метрики модели на независимых данных \cite{cross-validation-non-main}.
    \subsection{Задача классификации}
В рамках выпускной квалификационной работы будет решаться одна из задач обучения с учителем~--- задача классификации. Задача отличается от других тем, что выходные данные представляют из себя конечное множество, называемое метками классов \cite{classification-task}. Таким образом, обученная модель должна выдавать для входных данных одну из меток классов из обучающей выборки. Существует несколько видов задачи классификации: двухклассовая, многоклассовая, непересекающиеся классы, пересекающиеся классы. В выпускной квалификационной работе решалась задача двухклассовой классификации с непересекающимися классами. Для решения задачи классификации существует большое количество методов, например: байесовский классификатор, нейронная сеть, решающие деревья и так далее.
\section{Система контроля версий Git}
Данные для обучения и оценки модели машинного обучения в рамках выпускной квалификационной работы были собраны из сервиса GitHub основанного на системе контроля версий Git. В данном разделе будет рассказано об устройстве данной системы контроля версий.
    \subsection{Системы контроля версий}
Система контроля версий (в дальнейшем может использоваться как VCS от английского Version Control System)~--- инструмент, позволяющий сохранять версии файлов и возвращаться к одной из сохранённых версий \cite{vcs-definition}.

История систем контроля версий начинается с появления первых локальных систем контроля версий, например Revision Control System (RCS). Причиной их появление служило то, что раннее сохранять версии приходилось вручную, создавая папки и копируя файлы из одной папки в другую. Разработчики локальных систем контроля версий стремились автоматизировать сохранение версий измененных файлов, что и привело к созданию RCS. Данная VCS хранила информацию обо всех изменениях выбранных для хранения файлов в специальном хранилище, которое называется репозиторий (repository). Но, команды по разработке программного обеспечения непрерывно росли. И важной частью процесса разработки стало взаимодействие программистов между собой. Использование локальных систем контроля версий не предусматривало простой способ обмена версиями.

Следующим этапом развития систем контроля версий стало создание централизованных систем контроля версий. Их основным отличием от локальных VCS является то, что информация о версиях хранится на сервере. Теперь, чтобы сохранить изменения, нужно отправить их на сервер. Но в то же время, клиенты могут скачать любую версию с сервера. Тем самым разработчики могут с лёгкостью взаимодействовать между собой. Примером централизованных систем контроля версий являются Perforce, Subversion (SVN), Concurrent Versions System (CVS). Данные VCS были стандартным решением для хранения версий. Но, коммуникация между разработчиками всегда проходила через сервер. Таким образом, существует единая точка отказа~-- сервер. Если у клиента теряется доступ к серверу, то он не может сохранять версии своих локальных изменений.

В данный момент системы контроля версий находятся на этапе распределенных систем контроля версий, которые стали заменять собой централизованные системы. Их особенность состоит в том, что теперь клиенты скачивают с сервера не только одну версию, а весь репозиторий целиком, и сами являются сервером. Таким образом, у каждого пользователя распределенной системы контроля версий локально находится полная копия репозитория на момент синхронизации. В таком случае разработчик может сохранять свои изменения в локальный репозиторий, как это происходило с локальными системами контроля версий. А затем, когда появляется соединение с сервером, он может отправить свои изменения файлов на сервер. С помощью такой системы пропадает единая точка отказа, которая присутствовала в централизованных системах контроля версий. Существует большое количество распределенных систем контроля версий, самые популярные из них: Git, Mercurial \cite{best-vcs}. 

В последствии стали появляться сервисы, которые позволяют арендовать сервера для хранения репозиториев, многие из них позволяют делать это бесплатно. Один из самых популярных сервисов является GitHub, который использует распредененную систему контроля версий Git. Важно заметить, что на январь 2020 года у этого сервиса арендовали более чем 28 миллионов репозиториев \cite{github-repo-count}. Каждый из них содержит множество версий кода, которые неявно хранят в себе шаблоны поведения разработчиков, настройки их окружения и другие интересные для анализа данные. В рамках данной работы для обучения и анализа математической модели использовался приведенный сервис.
    \subsection{Система контроля версий Git}
Для того, чтобы получать и анализировать данные из системы контроля версий Git, следует изучить то, как она устроена. Большинство операций в данной VCS происходит локально. В повседневном использовании взаимодействие с сервером производится операциями копирования изменений с сервера или отправкой локальных изменений на сервер. Конечно, есть и другие операции, например, получение списка веток у репозитория на сервере, но такие операции используются редко. Поэтому, мы внимательно рассмотрим как происходит локальная работа с системой контроля версий Git. Большая часть информации была взята из одной из основных книг по приведенной VCS \cite{pro-git}.

Репозиторий системы контроля версий Git состоит из трех частей: рабочая копия, область подготовки и Git директория \cite{pro-git}. 

Git директория (git directory)~--- это основная часть репозитория, без которой система контроля версий не может нормально функционировать. Она используется для хранения версий файлов в репозитории, а также для хранения мета-данных об этих версиях, например, дата создания версии. Каждый снимок представляет из себя бинарный объект, с помощью которого можно восстановить конкретную версию. Отличительной особенностью системы контроля версий Git является то, что она хранит не дельты изменений файлов, как, например, меркуриал. Вместо дельт изменений Git использует снимки состояний и хранит их в сжатых бинарных объектах \cite{pro-git}. С таким подходом Git позволяет быстро переключаться между различными версиями, так как не нужно применять дельты изменений на последнее сохраненное состояние.

Рабочая копия (working copy)~--- это снимок состояния репозитория вместе с новыми изменениями, которые не были перенесены в область подготовки. Для получения рабочий копии Git распаковывает сжатые бинарные объекты, которые хранятся в Git директории \cite{pro-git}. Рабочая копия используется для работы с файлами, которые хранятся в системе контроля версий. Для сохранения произведенной работы над этими файлами пользователь VCS должен перенести их в область подготовки.

Область подготовки (staging area)~--- содержит в себе информацию об изменениях, которые будут добавлены как новая версия в Git \cite{pro-git}. 

Исходя из информации выше следует, что для того, чтобы сохранить новую версию файла в систему контроля версий Git требуется: выбрать снимок состояния репозитория для обновления, сделать нужные изменения в файлах, перенести эти изменения в область подготовки и сделать операцию коммит (commit), которая создаст новую версию на основе предыдущей, включая новые изменения. После операции коммита будет создана сущность, которая так же называется коммит (commit). Следует подчеркнуть, что Git всегда создает новые версии (коммиты), а не модифицирует предыдущие. Модификация уже сохраненных версий невозможна \cite{pro-git}.

Коммит в системе контроля версий Git является не просто снимком изменений репозитория. Он состоит из трех частей: ссылки на бинарный объект версии, мета-информации (автор коммита, время коммита, сообщение введенное при коммите и так далее), идентификаторы родительских коммитов. Каждый коммит (за исключением крайних случаев, например, первого коммита в репозитории) имеет одного или более родительских коммитов. То, на какие коммиты будет ссылаться вновь созданный коммит, зависит от операции, которая была произведена. Все эти три части соединяются и из них генерируется уникальный идентификатор \cite{pro-git}. Для создания уникального идентификатора используется SHA хэш. Конечно, такой хэш подвержен коллизиям, но Git пренебрегает ими.

В системе контроля версий Git есть важная функциональность, которая называется ветвление. Эта функциональность позволят создавать специальные метки, которые <<цепляются>> за коммиты. Эти метки именуются ветками. Они позволяют производить параллельную работу над репозиторием, не беспокоя других пользователей проекта. Есть две особенные ветки: <<HEAD>> и <<master>>. Они создаются при создании репозитория в данной VCS. Особенность <<HEAD>> в том, что она <<цепляется>> не за коммит, а за другую ветку. И дальнейшие операции коммита будут двигать <<HEAD>> и ветку, за которую <<зацеплена>> <<HEAD>>, на новый коммит. В условиях выпускной квалификационной работы другие ветки не рассматривались.

При внимательном рассмотрении можно заметить, что репозиторий системы контроля версий Git представляет из себя ациклический ориентированный граф, где вершинами являются коммитами, а ребрами отношение <<быть родителем>>.
\section{Платформа для создания интегрированных сред разработки IntelliJ}
С каждым годом количество написанного кода в мире непрерывно растет. Количество кода, которое должен писать каждый разработчик тоже увеличивается. Поэтому, более чем 20 лет назад люди стали задумываться о том, что некоторые шаги разработки можно автоматизировать, сделать проще, чем использование встроенного в операционную систему блокнота вместе с командной строкой. Стали появляться первые интегрированные среды разработки(далее может использоваться как IDE от английского Integrated development environment), например, Turbo Pascal, который включал в себя не только текстовый редактор с подсветкой, но и функционал запуска, отладки написанного приложения.

За последние годы появилось достаточно большое количество различных интегрированных сред разработки, например, Eclipse, Visual Studio, Visual Studio Code и другие. Но одной из самых значимых для информационных технологий разработок стало создание компанией JetBrains платформы IntelliJ, на основе которой можно создавать интегрированные среды разработки под разные языки, платформы. На её основе были созданы одни из самых популярных IDE в мире: IntelliJ IDEA, Android Studio, PyCharm и другие \cite{top-ide}.

Платформа IntelliJ представляет из себя платформу для создания инструментов для разработки \cite{intellij-top}. IntelliJ является продуктом с открытым исходным кодом. В её базовые компоненты входят графический интерфейс, виртуальная файловая система, текстовый редактор, интеграция с различными системами контроля версий \cite{intellij-top}. Платформа предоставляет возможность расширять её функциональность с помощью плагинов (от английского plugin), например, добавлять различные визуальные эффекты, утилиты статического анализа и много другого. В данной работе будет создан один из таких плагинов, расширяющих функциональность существующих IDE на основе IntelliJ платформы.


\section{Формальная постановка задачи предсказания забытых для модификации файлов на основе Git репозитория}
Введем понятие репозиторий (от английского repository)~-- это ориентированный ациклический граф, где каждое ребро представляет из себя отношение <<быть родителем>>. Вершину данного графа будем называть коммит (от английского commit). Коммит содержит в себе свойства: множество файлов $Files \subseteq File^k$ и мета-информацию (время создания, автор, название коммита, названия файлов). $File \in \mathbb{N}$ -- идентификатор файла в репозитории.\\
\subsection{Требования к модели рекомендации}\label{ml-model-req}
Пусть нам даны репозиторий и коммит из него. Файлы, которые пользователь должен был закоммитить~--- $TargetCommitFiles \subseteq File^k$. Требуется по данным множеству файлов, которые пользователь закоммитил в данный момент, $CommitFiles \subseteq TargetCommitFiles$, мета-информации о коммите и всех потомках коммита возвращать файлы из множества $Target = TargetCommitFiles \diagdown CommitFiles$. Так как результат работы решающей функции будет показан в пользовательском интерфейсе, было решено ограничить число показываемых файлов каким-то числом (иначе пользователь может не смотреть предложенные рекомендации). Было взято число пять на основе результатов работы функции баесовского среднего, описанной в секции \ref{chapter-2-bayes}. Её качество не сильно росло при небольшом увеличении этой границы. Но достаточно сильно падало при рекомендации четырех файлов. Важным требованием к модели рекомендации была её точность. Она должна составлять не менее 0,5 на собранном наборе данных. Измеряется точность здесь таким образом: если один из файлов, предсказанных моделью, присутствует в $Target$, то это считается как $True Positive$, если все предсказанные файлы не содержатся во множестве $Target$, то это считается как $False Positive$. Формула расчета точности:
    $$Precision = \frac{True Positive}{True Positive + False Positive}$$
Точность была выбрана, как метрика, исходя из того, что пользователи такого типа утилит в большей степени отрицательно относятся $False Positive$, чем к остальным ошибкам \cite{microsoft-false-positive}.
\subsection{Требования к реализации плагина для IntelliJ платформы}\label{impl-req}
Требуется разработать плагин для платформы IntelliJ, который во время пользовательского коммита будет рекомендовать пользователю модифицировать и добавлять в коммит файлы из репозитория. Плагин должен быть основан на модели, требования к которой изложены в \ref{ml-model-req}. В худшем случае, потребление оперативной памяти должно быть не более 10 Мегабайт. Такое требование было принято в связи с тем, что число плагинов, которые поставляются вместе с платформой достаточно велико, если каждый из них будет потреблять большое количество оперативной памяти, то её категорически не будет хватать пользователю.

\section{Обзор материалов посвященных анализу Git репозиториев и поиску зависимостей в них}
Перед началом выполнения выпускной работы были проанализированы несколько статей на тему дипломной работы и смежные темы. В мировом индексе представлено множество работ, где рассказано о том, как можно использовать исторические данные в процессе разработки программного обеспечения с целью повышения качества этого процесса. Среди них был подход использования кодовой базы для поиска логически связанных модулей, чтобы отследить, какие файлы изменяются вместе \cite{logical-modules}. В статье \cite{source-change} автор разрабатывал систему предсказаний о том, какие изменения внесет разработчик в кодовую базу. Были проанализированы статьи, которые не имеют непосредственного отношения к выпускной работе, но подходы из этих статей использовались при разработке модели предсказаний. Например, одна из таких статей \cite{project-memory}. В данной статье авторы разработали приложение <<Hipikat>>, позволяющее новым участникам быстрее ознакомится с программной системой, с которой им предстоит работать. В ходе анализа этих и других статей не было найдено решений поставленной нами задачи. Но в данном множестве статей показано, как использовать Git репозиторий для извлечения информации о проекте и поиска зависимостей между файлами, что и использовалось в работе.

\chapterconclusion
В представленной главе были рассмотрены основные моменты предметной области, которая будет использована при создании системы предсказания забытых для модификации файлов на основе Git репозитория. Было рассмотрено, что такое машинное обучение, каких видов оно бывает, какие задачи решает. Так как работа использует понятие Git, были рассмотрены системы контроля версий и более подробно Git. Была рассмотрена одна из самых популярных платформ для создания интегрированных сред разработки IntelliJ. На основе данных определений и понятий была поставлена формальная задача предсказания забытых для модификации файлов на основе Git репозитория.