\section{Создание искусственного набора данных}
Перед началом обучения моделей машинного обучения следует создать набор данных (датасет), с помощью которого модели и должны обучаться.
    \subsection{Исходные данные}
Для получения необработанных данных использовалось названый раннее сервис по хранению репозиториев~--- GitHub. Для последующего анализа было скопировано около 50 репозиториев. История этих репозиториев анализировалась с помощью встроенных в Git комманд (например, git log). Система контроля версий Git выдает историю репозитория, начиная от самых новых коммитов к самым старым. Чтобы упростить отслеживание удаления и переименования файлов, было принято решение перевернуть историю и отслеживать ее, начиная от самых старых к самым новым коммитам.
    \subsection{Тренировочный датасет}
Когда история репозитория получена, ее следует обработать таким образом, чтобы алгоритм понимал, когда нужно предсказывать файл, когда нет. Для этого введем лемму о полном коммите.
    \subsubsection{Лемма о полном коммите}
Сделаем такое предположение: большинство коммитов в любом репозитории уже содержат полный набор файлов. Учитывая, что коммитов много, коммиты с неполным набором файлов не повлияют на качество рекомендаций. Тогда если коммит, взятый из репозитория, имеет полный набор файлов, то при удалении файла из этого коммита набор будет неполным. На основе данного предположения и был построен датасет.
    \subsubsection{Формат датасета}
Сгенерированный датасет состоит из строк, где любая отдельная строка содержит несколько частей:
    \begin{itemize}
		\item Информация о коммите: автор коммита, время коммита, файлы в нем и т.д.
		\item Файл из репозитория.
		\item Единица, если файл должен быть предсказан, иначе~-- ноль.
	\end{itemize}
    \subsubsection{Выходные данные алгоритма}
 Выходные данные алгоритма строятся следующим образом: для каждого коммита размера $N$ каждое из его подмножеств размера $N - 1$ берется в качестве первой части, а оставшийся файл считается правильным выходным сигналом~-- второй частью строчки датасета (единицей). В то же время, система не должна ничего рекомендовать для оригинального коммита, поэтому необходимо добавить в датасет некоторое количество строк, где первая часть является текущим коммитом, а вторая часть содержит <<связанный>> файл не из текущего коммита. У такой строчки выходные данные будут равны нулю. <<Связанный>> файл~-- это файл, который был в одном и том же коммите с любым из файлов из текущего коммита хотя бы один раз.
    \subsection{Тестовый датасет}
Тестовый набор данных имеет тот же формат, что и обучающий набор данных. Самое главное~-- никогда не проверять качество системы на данных, которые использовались для обучения этой системы. Поэтому проводится проверка каждого репозитория на $k$ последних коммитах и обучение его на остальной истории. Это, также, имеет и практическое значение~-- наша система всегда будет обучаться на данных, полученных в прошлом: значит нам нужно хорошо уметь делать рекомендации в будущем.
    \subsection{Оценка качества}
Главная цель нашей системы~-- рекомендовать полный набор файлов по данному коммиту. Следует отметить, что когда разработчик использует нашу систему, важно не давать неверные рекомендации. Если система не уверена в конкретной рекомендации, то лучше молчать, чем нарушать рабочий процесс разработчика. Исходя из этого предположения, система должна попытаться свести к минимуму количество ложных срабатываний($FalsePositive$) и максимально увеличить количество истинных положительных результатов ($TruePositive$). Необходимо подумать о том, насколько хороши рекомендации нашей модели со стороны пользователя. Как было приведено в пункте \ref{ml-model-req} при оценке качества решающей функции минимизировалась мера точности.

\section{Разработка и обучение моделей предсказания забытых для модификации файлов на основе Git репозитория}
    \subsection{Мера Серенсена}\label{chapter3-coef}
В качестве первой модели предсказания забытых для модификации файлов использовалась модель приведенная в пункте \ref{chapter-2-coef}. 

Было сделано улучшение данной модели: файлом-кандидатом на рекомендацию выбирались только <<связанные>> файлы. Данное улучшение позволило сократить время подсчета предсказания и сэкономить оперативную память, которая потреблялась для хранения истории репозитория. С использованием такой оптимизации можно хранить в оперативной памяти информацию только о тех коммитах, в которых модифицировались файлы из текущего коммита. Данное улучшение использовалось во всех последующих моделях.

Во время использования данной модели было выяснено, что в репозиториях, состоящих из более чем 10000 коммитов, содержащих более чем 1000 файлов, потребление оперативной памяти на хранение истории могло в крайних случаях не удовлетворять требованию, поставленному в пункте \ref{impl-req}. В целях выполнения поставленной задачи, к каждому следующему алгоритму были добавлены два гипер-параметра: $MAX\_RELATED\_FILES\_COUNT$, $MAX\_HISTORY\_COMMIT\_SIZE$. 

$MAX\_RELATED\_FILES\_COUNT$~--- ограничивает количество файлов-кандидатов. С использованием данного гипер-параметра можно ограничить количество коммитов, которые будут хранится в оперативной памяти. Реализовано это с помощью алгоритма поиска в ширину \cite{alghorithms}.

$MAX\_HISTORY\_COMMIT\_SIZE$~--- ограничивает максимальное количество файлов в коммитах из истории. Модель не будет рассматривать коммиты, которые содержат более чем $MAX\_HISTORY\_COMMIT\_SIZE$ файлов. Таким образом, такие коммиты можно не хранить в оперативной памяти.

Как уже было сказано в пункте \ref{chapter-2-coef} в дополнение к приведенным выше гипер-параметрам мера Серенсена имеет один гипер-параметр: $threshold$. Подбор данных гипер-параметров во всех приведенных в данной главе алгоритмах осуществлялся одним из самых используемых в машинном обучении способом ~--- поиск по решетке \cite{claesen2015hyperparameter}.

В пункте \ref{coef-quality} будет проведен анализ качества данной решающей функции.
    \subsection{Ассоциативные правила}
Следующей реализованной моделью была модель получения ассоциативных правил, которая описана в пункте \ref{chapter2-rules}, с использованием алгоритма Apriori, описанного в пункте \ref{chapter2-apriori}. Модель была реализована автором работы на языке программирования Python версии 2.7.10.

Данный метод нельзя ограничить с использованием гипер-параметров $MAX\_RELATED\_FILES\_COUNT$, $MAX\_HISTORY\_COMMIT\_SIZE$, так как правильное получение ассоциативных правил требует обработки всего репозитория целиком. Для подбора поддержки и достоверность, также, как в пункте \ref{chapter3-coef} использовался метод поиска по решетке. Стоит отметить, что подбор данных гипер-параметров должен осуществляться для каждого репозитория в отдельности, чтобы учитывать их особенности (например, общее число коммитов в репозиториях может существенно отличаться).

Получение ассоциативных правил для больших репозиториев может длится достаточно долго. Также, для каждого репозиторя нужно подбирать гипер-параметры алгоритма. Все это нужно делать на стороне пользователя, поэто было принято решение не использовать данную решающую функцию в плагине для платформе IntelliJ в связи с тем, что придется предподсчитывать ассоциативные правила у каждого пользователя отдельно для всех его репозиториев, такое решение может занимать много места у пользователя на диске. Конечно, в условиях поставленной задачи не звучало ограничений на использование не оперативной памяти, но об этом тоже следует задумываться. В дополнение к этому, на основе анализа проведенного в пункте \ref{rules-quality} (которое не ограничивалось в потреблении памяти локального хранилища), решение не использовать данную модель в плагине было принято окончательно.

    \subsection{Байесовское среднее}\label{chapter3-bayes}
Третьим методом, который был реализован, является байесовское среднее. Метод более подробно приведен в пункте \ref{chapter-2-bayes}. В качестве гипер-параметров данного метода выступают: $threshold$, $MAX\_RELATED\_FILES\_COUNT$, $MAX\_HISTORY\_COMMIT\_SIZE$, а также функция голоса одного файла за другой. Метод был реализован автором статьи с использованием языка программирования Kotlin под Java Virtual Machine платформу.

Гипер-параметры $threshold$, $MAX\_RELATED\_FILES\_COUNT$, $MAX\_HISTORY\_COMMIT\_SIZE$, как и в пункте \ref{chapter3-coef} подбирались с использованием алгоритма поиска по решетке. В то время, как функцию голоса напрямую таким способом подобрать не получится, следует в начале определить множество функций голоса. Автором статьи было создано более десяти таких функций, ниже будет разобрана самая лучшая по качеству из них.

Одна из функций голоса, которая показала лучший результат на искусственном наборе данных (можно увидеть в пункте \ref{bayes-quality-offline}). Для каждого файла из текущего коммита 20 последних коммитов, содержащих этот файл, извлекаются из истории. После этого каждый из этих извлеченных коммитов голосует за файлы, содержащиеся в нем (исключая файлы от текущего коммита). Величина голоса рассчитывается по формуле: 
    $$\min(1.0, \frac{{commit\_size}}{{size}})$$
$commits\_size$ --  максимальное число файлов в голосующем коммите, чтобы получить максимальную величину голоса (алгоритмом поиска по решетке было выбрано число 8),\\
$size$ -- число файлов в голосующем коммите\\
Результаты из разных файлов складываются. Файл будет рекомендован, если его оценка выше чем порог, который был подобран алгоритмом поиском по решетке и равен $0,55$.

В пункте \ref{bayes-quality-offline} будет проведен анализ качества данной решающей функции на искусственном наборе данных. Приведенная решающая функция также была использована в качестве модели предсказаний в плагине для IntelliJ платформы, поэтому была собрана статистика и оценено качество на ней в пункте \ref{bayes-quality-online}. 
    \subsection{Случайный лес}
Последним методом, который был использован в работе, является случайный лес. Подробнее о самом алгоритме рассказано в пункте \ref{chapter2-forest}. Алгоритм обучения использовался из библиотеки scikit-learn. В данном алгоритме присутствуют гипер-параметры: максимальная высота деревьев, количество деревьев и минимальное число примеров для создания листа. Данные гипер-параметры подбирались с помощью библиотеки hyperopt. Оставшиеся гипер-параметры: $threshold$, $MAX\_RELATED\_FILES\_COUNT$, $MAX\_HISTORY\_COMMIT\_SIZE$~-- подбирались с помощью метода поиска по сетке. 

Данный метод отличается от предыдущих тем, что он основан на выделении признаков из данных. В рамках данной работы автором было выделено более 50 различных признаков, которые описывают файл-кандидат по отношению к текущему коммиту. Одним из этапов обучения модели была фильтрация этих самых признаков. Фильтровались они с помощью имеющейся в scikit-learn информации, называемой $feature\_importance$. Более конкретно, в имеющийся набор признаков у каждой строчки датасета добавляется фиктивный сгенерированный случайный признак. И все признаки, величина которых в $feature\_importance$ была меньше, чем у случайного признака, не использовались.

Таким образом, признаки отобранные при обучении случайного леса приведены в списке ниже:
\begin{itemize}
    \item Максимальное значение функции $f(file)$, для всех файлов из пользовательского коммита, где $f$~-- это число коммитов, где файл $file$ и кандидат на предсказание были вместе модифицированы.
    \item Сумма значений функции $f(file)$, для всех файлов из пользовательского коммита, где $f$~-- это число коммитов, где файл $file$ и кандидат на предсказание были вместе модифицированы.
    \item Минимальное расстояние между пользовательским коммитом и коммитом из истории репозитория, где были модифицированы файл из коммита и кандидат на рекомендацию.
    \item Максимальное расстояние между пользовательским коммитом и коммитом из истории репозитория, где были модифицированы файл из коммита и кандидат на рекомендацию.
    \item Среднее расстояние между пользовательским коммитом и коммитом из истории репозитория, где были модифицированы файл из коммита и кандидат на рекомендацию.
    \item Число файлов в пользовательском коммите.
    \item Совершал ли автор пользовательского коммита коммит содержащий в себе кандидата на рекомендацию.
    \item Размер максимального по мощности множества файлов из текущего коммита, каждый файл из которого присутствовал с кандидатом на рекомендацию в одном коммите.
    \item Размер минимального по мощности множества файлов из текущего коммита, каждый файл из которого присутствовал с кандидатом на рекомендацию в одном коммите.
    \item Максимальная длина наибольшего общего префикса абсолютного пути между файлом из текущего коммита и кандидатом на рекомендацию.
    \item Максимальная длина наибольшего общего префикса пути относительно корня репозитория между файлом из текущего коммита и кандидатом на рекомендацию.
\end{itemize}

Важным моментом в использовании обученной модели является то, что ее обучение происходило с использованием языка Python. Как было сказано в пункте \ref{ij-platform-req} плагин должен использовать языки программирования основанные на JVM платформе. Основная версия языка программирования Python таковой не является, поэтому модель, обученная с использованием библиотеки scikit-learn, была сериализована с использованием библиотеки pickle и десериализована в код на языке программирования Java. Известно, что модель использует множество решающих деревьев, которые можно десериализовать в код состоящий из операций $if$ и $else$, что и было сделано. 

В пункте \ref{forest-quality-offline} будет проведен анализ качества данной решающей функции на искусственном наборе данных. Приведенная решающая функция также была использована в качестве модели предсказаний в плагине для IntelliJ платформы, поэтому была собрана статистика и оценено качество на ней в пункте \ref{forest-quality-online}. Более того, данная модель была внедрена во многие IDE основанные на IntelliJ платформе (подробнее в четвертой главе).
\section{Оценка качества обученных моделей на основе искусственного набора данных}
    \subsection{Мера Серенсена}\label{coef-quality}
    \subsection{Ассоциативные правила}\label{rules-quality}
В таблице \ref{ar-offline-result-table} можно увидеть пример качества обученных моделей с приведенными гипер-параметрами на репозитории intellij-community \cite{ij-community}. В данной таблице представлены одни из лучших полученных решений. Можно заметить, что ни одно из полученных решений не удовлетворяет задаче, поставленной в пункте \ref{ml-model-req}, даже на одном репозитории. В остальных рассмотренных репозиториях результат был относительно похожий.
        \begin{table}[!h]
        \caption{Точность части исследованных моделей на ассоциативных правил}\label{ar-offline-result-table}
        \centering
        \begin{tabular}{|l|c|}\hline
        \multicolumn{1}{|c|}{\textbf{Модель ассоциативных правил}} & \textbf{Точность}\\\hline
        Граница применения 0,25; размер набора 3; поддержка 0,08 & 0,18\\\hline
        Граница применения 0,25; размер набора 5; поддержка 0,01  & 0,24 \\\hline
        Граница применения 0,25; размер набора 3; поддержка 0,1  & 0,22\\\hline
        \end{tabular}
        \end{table}
    \subsection{Байесовское среднее}\label{bayes-quality-offline}
В таблице \ref{bayes-offline-result-table} представлена оцененная точность моделей байесовского среднего с несколькими функциями голоса. Видно, что функция голоса, представленная в пункте \ref{chapter3-bayes} выполнила требования поставленные в пункте \ref{ml-model-req} на основе искусственного датасета. Данная функция использовалась в качестве модели рекомендаций в плагине для платформы IntelliJ ~-- GitAlso, реализованным автором выпускной квалификационной работы.
        \begin{table}[!h]   
        \caption{Точность части исследованных моделей на основе байесовского среднего}\label{bayes-offline-result-table}
        \centering
        \begin{tabular}{|l|c|}\hline
        \multicolumn{1}{|c|}{\textbf{Функция голоса}} & \textbf{Точность}\\\hline
        Количество файлов в коммите & 0,47\\\hline
        Количество файлов в коммите с ограничением  & \uline{0,53} \\\hline
        Взвешанное расстояние по времени от текущего коммита  & 0,32\\\hline
        Константный голос  & 0,31\\\hline
        Линейная комбинация предыдущих функций голоса  & 0,42\\\hline
        \end{tabular}
        \end{table}
    \subsection{Случайный лес}\label{forest-quality-offline}
В таблице \ref{rf-offline-result-table} представлена оцененная точность моделей случайного леса с различными гипер-параметрами алгоритма. Все приведенные модели выполняют требования, поставленные в задаче \ref{ml-model-req}. Стоит обратить внимание, что модель с максимальной высотой равной 16 и числом деревьев равным 100 показывает меру на искусственном датасете лучше, чем модель с максимальной высотой равной 13 и числом деревьев равным 100, но данная модель не использовалась, так как занимает большое количество оперативной памяти и вместе с хранением части история репозитория требования, поставленные в пункте \ref{impl-req} не выполнялись. 

Модель случайного леса использовалась в качестве модели рекомендаций в плагине для платформы IntelliJ~-- ChangeReminder, реализованным автором выпускной квалификационной работы. Данный плагин был внедрен в некоторые IDE основанные на платформе IntelliJ, начиная с версии 2019.2.
        \begin{table}[!h]
        \caption{Точность части исследованных моделей на случайного леса}\label{rf-offline-result-table}
        \centering
        \begin{tabular}{|l|c|}\hline
        \multicolumn{1}{|c|}{\textbf{Модель случайного леса}} & \textbf{Точность}\\\hline
        Максимальная высота 11; число деревьев 50 & 0,56\\\hline
        Максимальная высота 13; число деревьев 100 & \uline{0,61} \\\hline
        Максимальная высота 16; число деревьев 100  & \textbf{0,63} \\\hline
        \end{tabular}
        \end{table}

\section{Оценка качества обученных моделей на основе собранной статистики}
На основе нескольких моделей, из приведенных в секции \ref{chapter2-models}, были реализованы плагины для платформы IntelliJ, подробнее о которых рассказано в четвертой главе. И, конечно, интересно узнать, насколько выполняются требования поставленные в пункте \ref{ml-model-req} на практике. Для этого была собрана и проанализирована статистика (подробнее о том, как статистика было собрана можно увидеть в секции \ref{stats-main}). Результаты анализа собранной статистики рассмотрены в данной секции.
    \subsection{Байесовское среднее}\label{bayes-quality-online}
Модель байесовского среднего использовалась в плагине, представленном в пункте \ref{git-also-main}. Статистика, которая собиралась на основе пользовательского взаимодействия с плагином представлена в пункте \ref{gitalso-stats}.

Для того, чтобы подсчитать качество используемой модели, следует выделить, какие предсказания следует считать $TruePositive$, какие $FalsePositive$, затем подставить эти значения в формулу \ref{precision-formula}. На основе модели собираемой статистики было решено, что $FalsePositive$~--- это событие, когда пользователь нажал на кнопку Commit Anyway. Это значит, что рекомендация или была неправильной, или рекомендация не нужна пользователю в данный момент времени, в обеих ситуациях следует считать, что модель ошиблась. Предсказания являющиеся $TruePositive$ ~--- это предсказания, в которых пользователь нажал на кнопку Cancel Commit и в следующем коммите добавил один или несколько файлов из рекомендации, иначе, если пользователь нажал на кнопку Cancel Commit и не добавил в следующий коммит файл из рекомендации, это будет считаться $FalsePositive$ (скорее всего, это являлось случайным нажатием, которое еще больше может раздражать пользователя, что его коммит не завершен).

На основе статистики присланной более чем 100 пользователями и оценке, которую мы ввели выше, было подсчитано, что точность решающей функции примерно равно $0,48$, что практически удовлетворяет условию, поставленному в пункте \ref{ml-model-req}, но такое отклонение было посчитано небольшим для модели, обученной на искусственном датасете. Таким образом, модель показало хороший результат.
    \subsection{Случайный лес}\label{forest-quality-online}
Модель случайного леса использовалась в плагине, представленном в пункте \ref{changereminder-main}. Статистика, которая собиралась на основе пользовательского взаимодействия с плагином представлена в пункте \ref{changereminder-stats}.

Как и в пункте \ref{bayes-quality-online} следует определить, какое предсказание является $FalsePositive$, а какое $TruePositive$. В реализации данного плагина это сделать сложнее, так как он уже не является хуком, который выполняется в момент пользовательского коммита. Он показывает предсказания перед тем, как пользователь нажмет кнопку Commit. В связи с этим, было решено считать, что $TruePositive$~--- это предсказание, на которое посмотрел пользователь (раскрыл вершину в Local Changes), файл из которого пользователь добавил в следующий коммит. Иначе, это $FalsePositive$. 

На основе статистики присланной более чем 1000 пользователями и оценке, которую мы ввели выше, было подсчитано, что точность решающей функции примерно равно $0,24$, что намного хуже, чем качество на искусственном датасете, на котором случайный лес побеждал все предыдущие модели. Скорее всего, на точность предсказания повлияла реализация плагина ChangeReminder, а минно то, как плагин используется. GitAlso всегда работал так, как он был обучен, то есть во время пользовательского коммита. А в вершину, созданную плагином ChangeReminder пользователи смотрят не только перед коммитом. Для подтверждения данной гипотезы планируется проведение A/B эксперимента с решающими функциями случайного леса и байесовского среднего, чтобы определить, повлиял ли выбор решающий функции на такое качество, или повлияла именно реализация плагина.

A/B тестирование~--- это способ сравнения качества работы двух версий приложений. Проводится он так (и не только): части пользователей рекомендации дает решающая функция A, части пользователей~-- решающая функция B. На основе полученной статистики можно смотреть на то, как меняется поведение пользователя в зависимости от решающией функции. И в итоге выбрать для всех пользователей одну.
\chapterconclusion
В представленной главе было рассмотрено обучение и оценка качества моделей предсказания забытых для модификации файлов на основе Git репозитория. Было объяснено, как собирался и обрабатывался набор данных, как подсчитывалась метрика на обработанном датасете. Было показано, как реализованы модели на построения ассоциативных правил, байесовского среднего и случайного леса. Ассоциативные правила показали плохой результат на искусственном наборе данных. И вместе с отрицательными сторонами этой модели было решено не использовать ее в плагине для IntelliJ платформы. Модели байесовского среднего и случайного леса смогли выполнить требования, поставленные в пункте \ref{ml-model-req}, и пришлось наложить на модели некоторые ограничения по необходимой им части истории репозитория, чтобы выполнить требования к плагину для IntelliJ платформы представленные в пункте \ref{impl-req}. Даже с такими ограничениями модели показали хорошие результаты, поэтому были использованы, как способ предсказания забытых для модификации файлов на основе Git репозитория.